{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: Dataset: File exists\r\n",
      "--2022-06-17 23:21:57--  https://raw.githubusercontent.com/agtmwebtoon/automl-data-science/main/Dataset/sampled_dataset.csv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 6109441 (5.8M) [text/plain]\r\n",
      "Saving to: ‘Dataset/sampled_dataset.csv.1’\r\n",
      "\r\n",
      "sampled_dataset.csv 100%[===================>]   5.83M  11.7MB/s    in 0.5s    \r\n",
      "\r\n",
      "2022-06-17 23:21:59 (11.7 MB/s) - ‘Dataset/sampled_dataset.csv.1’ saved [6109441/6109441]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir Dataset\n",
    "!wget https://raw.githubusercontent.com/agtmwebtoon/automl-data-science/main/Dataset/sampled_dataset.csv -P Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import  r_regression, SelectKBest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from woodwork.logical_types import Categorical, Boolean\n",
    "from math import  ceil, log10, sqrt\n",
    "'''\n",
    "Add plt config\n",
    "@Author: MinHyung Lee\n",
    "@Since: 2022/05/24\n",
    "\n",
    "'''\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['figure.figsize'] = [12, 9]\n",
    "rcParams['font.size'] = 16\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "rcParams['figure.dpi'] = 600\n",
    "\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class AutoML:\n",
    "\n",
    "    '''\n",
    "    AutoML\n",
    "    @Author: MinHyung Lee\n",
    "    @Since: 2022/06/02\n",
    "    Find best parameter automatically\n",
    "    Just decide which columns is unusable\n",
    "    Find columns that consisted of String\n",
    "\n",
    "    and call\n",
    "\n",
    "    model.feed_input(raw_df, do_sampling=True, sample_size=20000)\n",
    "    model.feature_cleaning(unusable_col, string_col)\n",
    "    model.find_best_combination()\n",
    "\n",
    "\n",
    "    Finally It will search best parameter for you\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        self.df = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.best_param = None\n",
    "        self.model = None\n",
    "        self.score = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def feed_input(self, dataset, do_sampling, sample_size):\n",
    "        '''\n",
    "        feed_input\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        @dataset: raw dataframe for machine learning\n",
    "        @do_sampling: Flag that sampling the dataset\n",
    "        @sample_size: Sample size for random sampling\n",
    "        Set object's dataset\n",
    "        Also can random sampling by do_sampling option\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        self.df = dataset\n",
    "\n",
    "        if do_sampling:\n",
    "            self.sampling(sample_size)\n",
    "\n",
    "    def feature_cleaning(self, unused_column=[], string_column=[]):\n",
    "\n",
    "        '''\n",
    "        feature_cleaning\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        @unused_column: Features considered useless <list>\n",
    "        @string_column: Features consisted of String <list>\n",
    "        Drop unused column\n",
    "        Encode string value using ordinalEncoder\n",
    "        Find Na value and fill it my df.mean\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        self.df.drop(unused_column, axis=1, inplace=True)\n",
    "\n",
    "        # Encode string values\n",
    "        encoding = OrdinalEncoder()\n",
    "        encoding.fit(self.df[string_column])\n",
    "        self.df[string_column] = encoding.transform(self.df[string_column])\n",
    "        self.df.fillna(self.df.mean(), inplace=True)\n",
    "\n",
    "    def split_dataset(self, target):\n",
    "\n",
    "        '''\n",
    "        split_dataset\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/04\n",
    "        @target: Dataset <DataFrame>\n",
    "\n",
    "        '''\n",
    "\n",
    "        self.y = self.df[[target]].to_numpy()\n",
    "        self.X = self.df.drop([target], axis = 1)\n",
    "\n",
    "    def find_best_combination(self):\n",
    "\n",
    "        # Do feature selection (k = 1 .. size of feature)\n",
    "        # Do normalization (StandardScaler, RobustScaler, MinMaxScaler)\n",
    "        # Do PCA (explained_variance = 0..1)\n",
    "        # find best parameter by using different parameter\n",
    "\n",
    "        '''\n",
    "        find_best_combination\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        find best parameter and set best model\n",
    "        '''\n",
    "\n",
    "\n",
    "        self.split_dataset(\"Maximum Installs\")\n",
    "        param_k = np.arange(1, self.X.shape[1])\n",
    "        param_scale_method = ['s', 'r', 'm']\n",
    "        param_explained_var = np.linspace(0.01, 0.9999, 100)\n",
    "        param_model_type = ['l', 'k']\n",
    "        result = []\n",
    "        param_list = list(itertools.product(param_k, param_scale_method, param_explained_var, param_model_type))\n",
    "\n",
    "        for (k, scale_method, explained_var, param_model_type) in param_list:\n",
    "            X = self.feature_selection(k)\n",
    "            X = self.scaler(X, scale_method=scale_method)\n",
    "            X = self.pca(X, explained_var=explained_var)\n",
    "\n",
    "            X_train, X_test, y_train,  y_test = train_test_split(X, self.y, test_size = 0.2, random_state=7777)\n",
    "\n",
    "            mt = self.model_type(param_model_type)\n",
    "            _, score = mt(X_train, X_test, y_train, y_test)\n",
    "            result.append(score)\n",
    "\n",
    "        idx = np.argmin(result)\n",
    "        self.score = np.min(result)\n",
    "        self.best_param = param_list[idx]\n",
    "        self.set_model(self.best_param)\n",
    "\n",
    "    def set_model(self, best_param):\n",
    "\n",
    "        '''\n",
    "        set_model\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        @best_param: parameter set calculated by find_best_combination <list>\n",
    "        Set best model by using best parameter\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        (k, scale_method, explained_var, model_type) = best_param\n",
    "        X = self.feature_selection(k)\n",
    "        X = self.scaler(X, scale_method=scale_method)\n",
    "        X = self.pca(X, explained_var=explained_var)\n",
    "        self.X_train, self.X_test, self.y_train,  self.y_test = train_test_split(X, self.y, test_size = 0.2, random_state=7777)\n",
    "        mt = self.model_type(model_type)\n",
    "        reg, _ = mt(self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.model = reg\n",
    "\n",
    "\n",
    "    def sampling(self, sample_size=20000):\n",
    "        # Do random sampling\n",
    "        self.df = self.df.sample(n=sample_size, replace=True)\n",
    "\n",
    "    def feature_selection(self, k=5):\n",
    "\n",
    "        # Select best feature using selectKBest and scoring option is r_regression\n",
    "        select = SelectKBest(score_func=r_regression, k = k)\n",
    "        ret  = select.fit_transform(self.X, self.y)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def scaler(self, X, scale_method='s'):\n",
    "\n",
    "        '''\n",
    "        scaler\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        @scale_method:\n",
    "        s for standard scaler\n",
    "        r for robustscaler\n",
    "        m for minmaxscaler\n",
    "        Return Normalized feature\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        if scale_method == 's':\n",
    "            ret = StandardScaler().fit_transform(X)\n",
    "        elif scale_method == 'r':\n",
    "            ret = RobustScaler().fit_transform(X)\n",
    "        elif scale_method == 'm':\n",
    "            ret = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def pca(self, X, explained_var=0.9):\n",
    "\n",
    "        '''\n",
    "        pca\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        Calculate PCA\n",
    "        :return Feature reduction by PCA\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        # Set variance ratio to 0.9\n",
    "        pca = PCA(explained_var)\n",
    "        ret = pca.fit_transform(X)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def model_type(self, train_method):\n",
    "        '''\n",
    "        model_type\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        @train_method:\n",
    "        l for linear_regression\n",
    "        k for KNN_regression\n",
    "        Return train method\n",
    "\n",
    "        '''\n",
    "\n",
    "        if train_method == 'l':\n",
    "            return self.linear_regression\n",
    "        elif train_method == 'k':\n",
    "            return self.KNN\n",
    "\n",
    "\n",
    "    def make_subplot_layout(self, col_num=3):\n",
    "\n",
    "        '''\n",
    "        make_subplot_layout\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        Plot each features by subplots\n",
    "\n",
    "        '''\n",
    "\n",
    "        k = len(self.df.columns)\n",
    "        row_num = ceil(k/col_num)\n",
    "        for i in range(k) :\n",
    "            plt.subplot(row_num,col_num,i+1)\n",
    "            plt.hist(self.df.iloc[:,i])\n",
    "            plt.title(self.df.columns[i])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def linear_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        '''\n",
    "        linear_regression\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        Calculate MSE\n",
    "        :return\n",
    "        model: linearRegreesion model\n",
    "        score: logscale MSE\n",
    "        '''\n",
    "\n",
    "\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(X_train, y_train)\n",
    "        mean_error = 0\n",
    "        #Set Kfold for k == 5\n",
    "        cv = KFold(n_splits=5)\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in cv.split(X_test):\n",
    "\n",
    "            '''\n",
    "\n",
    "            @Author: MinHyung Lee\n",
    "            @Since: 2022/05/31\n",
    "            Validate each fold by using linear regression\n",
    "\n",
    "            '''\n",
    "\n",
    "            fold += 1\n",
    "            train_X, test_X = X_train[train_index], X_test[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_test[test_index]\n",
    "\n",
    "            reg.fit(train_X, train_y)\n",
    "\n",
    "            # Calculate mean error\n",
    "            mean_error += log10(mean_squared_error(y_test, reg.predict(X_test)))\n",
    "\n",
    "        return reg, mean_error / 5\n",
    "\n",
    "    def KNN(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        '''\n",
    "        KNN\n",
    "        @Author: MinHyung Lee\n",
    "        @Since: 2022/06/02\n",
    "        Find best neighbors by using GridSearch\n",
    "        Scoring method is negative MAE\n",
    "\n",
    "        :return\n",
    "        bestmodel // knn model\n",
    "        score // log scaled MSE\n",
    "\n",
    "        '''\n",
    "\n",
    "        knn = KNeighborsRegressor()\n",
    "        param_grid = dict(n_neighbors = np.arange(1, 30))\n",
    "\n",
    "        #Hyperparameter tuning by grid searching\n",
    "        grid_search = GridSearchCV(knn, param_grid, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        optimal_knn = grid_search.best_estimator_\n",
    "\n",
    "        return optimal_knn, log10(mean_squared_error(y_test, optimal_knn.predict(X_test)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('Dataset/sampled_dataset.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = AutoML()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#Declare unusable columns for drop\n",
    "#Declare columns that consist of string to encoding\n",
    "\n",
    "string_col = ['Category', 'Minimum Android', 'Content Rating', 'Ad Supported', 'In App Purchases', 'Installs']\n",
    "unusable_col = ['App Name', 'App Id', 'Minimum Installs', 'Price', 'Currency', 'Developer Id', 'Developer Website', 'Developer Email', 'Privacy Policy', 'Last Updated', 'Editors Choice', 'Scraped Time', 'Free', 'Rating Count', 'Rating', 'Size', 'Released']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Feed raw dataset\n",
    "# You can also random sampling\n",
    "model.feed_input(raw_df, do_sampling=True, sample_size=20000)\n",
    "model.feature_cleaning(unusable_col, string_col)\n",
    "\n",
    "# Do feature selection (k = 1 .. size of feature)\n",
    "# Do normalization (StandardScaler, RobustScaler, MinMaxScaler)\n",
    "# Do PCA (explained_variance = 0..1)\n",
    "# find best parameter by using different parameter\n",
    "\n",
    "model.find_best_combination()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "12.220636913574868"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_param\n",
    "model.score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}